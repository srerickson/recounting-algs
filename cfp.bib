
@online{noauthor_algorithmic_nodate,
	title = {Algorithmic Justic League},
	url = {https://www.ajlunited.org/},
	titleaddon = {Algorithmic Justic League},
	urldate = {2019-10-23},
	langid = {english},
	file = {Snapshot:/home/seth/Zotero/storage/AF3WTIRM/www.ajlunited.org.html:text/html}
}

@online{crawford_excavating_nodate,
	title = {Excavating {AI}},
	url = {https://www.excavating.ai},
	abstract = {An investigation into the politics of training sets, and the fundamental problems with classifying humans.},
	titleaddon = {-},
	author = {Crawford, Kate and Paglen, Trevor},
	urldate = {2019-10-03},
	langid = {american},
	file = {Snapshot:/home/seth/Zotero/storage/3JWPLYPL/www.excavating.ai.html:text/html}
}

@book{noble_algorithms_2018,
	title = {Algorithms of Oppression},
	abstract = {A revealing look at how negative biases against women of color are embedded in search engine results and algorithms Run a Google search for “black girls”...},
	publisher = {New York University Press},
	author = {Noble, Safiya},
	urldate = {2019-08-12},
	date = {2018},
	langid = {american},
	file = {Snapshot:/home/seth/Zotero/storage/GUP4QUJA/Algorithms of Oppression.html:text/html}
}

@book{eubanks_automating_2018,
	title = {Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor},
	isbn = {978-1-250-07431-7},
	shorttitle = {Automating Inequality},
	abstract = {{WINNER}: The 2018 {McGannon} Center Book Prize and shortlisted for the Goddard Riverside Stephan Russo Book Prize for Social Justice The New York Times Book Review: "Riveting."Naomi Klein: "This book is downright scary."Ethan Zuckerman, {MIT}: "Should be required reading."Dorothy Roberts, author of Killing the Black Body: "A must-read."Astra Taylor, author of The People's Platform: "The single most important book about technology you will read this year."Cory Doctorow: "Indispensable."A powerful investigative look at data-based discrimination—and how technology affects civil and human rights and economic equity The State of Indiana denies one million applications for healthcare, foodstamps and cash benefits in three years—because a new computer system interprets any mistake as “failure to cooperate.” In Los Angeles, an algorithm calculates the comparative vulnerability of tens of thousands of homeless people in order to prioritize them for an inadequate pool of housing resources. In Pittsburgh, a child welfare agency uses a statistical model to try to predict which children might be future victims of abuse or neglect.Since the dawn of the digital age, decision-making in finance, employment, politics, health and human services has undergone revolutionary change. Today, automated systems—rather than humans—control which neighborhoods get policed, which families attain needed resources, and who is investigated for fraud. While we all live under this new regime of data, the most invasive and punitive systems are aimed at the poor.In Automating Inequality, Virginia Eubanks systematically investigates the impacts of data mining, policy algorithms, and predictive risk models on poor and working-class people in America. The book is full of heart-wrenching and eye-opening stories, from a woman in Indiana whose benefits are literally cut off as she lays dying to a family in Pennsylvania in daily fear of losing their daughter because they fit a certain statistical profile.The U.S. has always used its most cutting-edge science and technology to contain, investigate, discipline and punish the destitute. Like the county poorhouse and scientific charity before them, digital tracking and automated decision-making hide poverty from the middle-class public and give the nation the ethical distance it needs to make inhumane choices: which families get food and which starve, who has housing and who remains homeless, and which families are broken up by the state. In the process, they weaken democracy and betray our most cherished national values.This deeply researched and passionate book could not be more timely.},
	pagetotal = {273},
	publisher = {St. Martin's Publishing Group},
	author = {Eubanks, Virginia},
	date = {2018-01-23},
	langid = {english},
	note = {Google-Books-{ID}: \_TdCDwAAQBAJ},
	keywords = {Computers / Social Aspects, Political Science / Public Policy / Social Services \& Welfare, Social Science / Poverty \& Homelessness, Social Science / Social Classes \& Economic Disparity}
}

@article{angwin_machine_2016,
	title = {Machine Bias},
	rights = {Copyright ©2019 {ProPublica}.},
	url = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
	journaltitle = {{ProPublica}},
	author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
	urldate = {2019-11-30},
	date = {2016-05-23},
	langid = {english},
	file = {Snapshot:/home/seth/Zotero/storage/U2HRIRZ3/machine-bias-risk-assessments-in-criminal-sentencing.html:text/html}
}

@article{posner_see_2018,
	title = {See No Evil},
	url = {https://logicmag.io/scale/see-no-evil/},
	abstract = {An investigation into how software wires global supply chains, and what code conceals.},
	journaltitle = {Logic Magazine},
	author = {Posner, Miriam},
	urldate = {2019-11-30},
	date = {2018-04-01},
	file = {Snapshot:/home/seth/Zotero/storage/FY9J82IP/see-no-evil.html:text/html}
}

@book{benjamin_race_2019,
	title = {Race After Technology: Abolitionist Tools for the New Jim Code},
	url = {http://politybooks.com/bookdetail/},
	abstract = {Book Detail},
	publisher = {Polity},
	author = {Benjamin, Ruha},
	urldate = {2019-11-30},
	date = {2019},
	langid = {american},
	file = {Snapshot:/home/seth/Zotero/storage/QFTYKWQH/bookdetail.html:text/html}
}

@article{seaver_algorithms_2017,
	title = {Algorithms as culture: Some tactics for the ethnography of algorithmic systems},
	volume = {4},
	issn = {2053-9517},
	url = {https://doi.org/10.1177/2053951717738104},
	doi = {10.1177/2053951717738104},
	shorttitle = {Algorithms as culture},
	abstract = {This article responds to recent debates in critical algorithm studies about the significance of the term “algorithm.” Where some have suggested that critical scholars should align their use of the term with its common definition in professional computer science, I argue that we should instead approach algorithms as “multiples”—unstable objects that are enacted through the varied practices that people use to engage with them, including the practices of “outsider” researchers. This approach builds on the work of Laura Devendorf, Elizabeth Goodman, and Annemarie Mol. Different ways of enacting algorithms foreground certain issues while occluding others: computer scientists enact algorithms as conceptual objects indifferent to implementation details, while calls for accountability enact algorithms as closed boxes to be opened. I propose that critical researchers might seek to enact algorithms ethnographically, seeing them as heterogeneous and diffuse sociotechnical systems, rather than rigidly constrained and procedural formulas. To do so, I suggest thinking of algorithms not “in” culture, as the event occasioning this essay was titled, but “as” culture: part of broad patterns of meaning and practice that can be engaged with empirically. I offer a set of practical tactics for the ethnographic enactment of algorithmic systems, which do not depend on pinning down a singular “algorithm” or achieving “access,” but which rather work from the partial and mobile position of an outsider.},
	pages = {2053951717738104},
	number = {2},
	journaltitle = {Big Data \& Society},
	shortjournal = {Big Data \& Society},
	author = {Seaver, Nick},
	urldate = {2018-12-10},
	date = {2017-12-01},
	langid = {english},
	file = {SAGE PDF Full Text:/home/seth/Zotero/storage/8D5M5PRL/Seaver - 2017 - Algorithms as culture Some tactics for the ethnog.pdf:application/pdf}
}

@article{the_information_maintainers_information_2019,
	title = {Information Maintenance as a Practice of Care},
	url = {https://zenodo.org/record/3251131#.XeRMS9FOnJE},
	abstract = {An invitation to participate in a broad ranging discussion that infuses information maintenance with practices, relationships, and ways of thinking and being that represent a coherent ethic of care.},
	author = {The Information Maintainers and Olson, D. and Meyerson, J. and Parsons, M. A. and Castro, J. and Lassere, M. and Wright, D. J. and Arnold, H. and Galvan, A. S. and Hswe, P and Nowviskie, B. and Russell, A. and Vinsel, L. and Acker, A.},
	urldate = {2019-12-01},
	date = {2019-06-17},
	doi = {10.5281/zenodo.3251131},
	file = {Zenodo Full Text PDF:/home/seth/Zotero/storage/BZ3HBHWP/The Information Maintainers et al. - 2019 - Information Maintenance as a Practice of Care.pdf:application/pdf}
}

@online{noauthor_experts_2017,
	title = {Experts on the Pros and Cons of Algorithms},
	url = {https://www.pewresearch.org/internet/2017/02/08/code-dependent-pros-and-cons-of-the-algorithm-age/},
	abstract = {Algorithms can save lives, make things easier and conquer chaos. But experts worry about governmental and corporate control of the data, and how algorithms can produce biased results and worsen digital divides.},
	titleaddon = {Pew Research Center: Internet, Science \& Tech},
	urldate = {2019-12-01},
	date = {2017-02-08},
	langid = {american},
	file = {Snapshot:/home/seth/Zotero/storage/WQGCFHCK/code-dependent-pros-and-cons-of-the-algorithm-age.html:text/html}
}

@article{rainie_code-dependent:_2017,
	title = {Code-dependent: Pros and cons of the algorithm age},
	volume = {8},
	shorttitle = {Code-dependent},
	journaltitle = {Pew Research Center},
	author = {Rainie, Lee and Anderson, Janna},
	date = {2017},
	file = {Full Text:/home/seth/Zotero/storage/ZUA6ZNGD/Rainie and Anderson - 2017 - Code-dependent Pros and cons of the algorithm age.pdf:application/pdf}
}

@software{clark_algorithmic_2019,
	title = {Algorithmic Awareness},
	rights = {{MIT}},
	url = {https://github.com/jasonclark/algorithmic-awareness},
	author = {Clark, Jason A.},
	urldate = {2019-12-01},
	date = {2019-10-22},
	note = {original-date: 2018-02-15T16:08:11Z},
	keywords = {algorithms, education, javascript}
}